{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Attention Mechanisms</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "    \"\"\"\n",
    "    query: (..., Tq, d_k)\n",
    "    key:   (..., Tk, d_k)\n",
    "    value: (..., Tk, d_v)\n",
    "    mask:  broadcastable to (..., Tq, Tk), with True=keep, False=mask-out\n",
    "    \"\"\"\n",
    "    d_k = query.size(-1)\n",
    "\n",
    "    # scores: (..., Tq, Tk)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) * (1.0 / math.sqrt(d_k))\n",
    "\n",
    "    if mask is not None:\n",
    "        # mask should be bool with True = allowed positions\n",
    "        scores = scores.masked_fill(~mask, torch.finfo(scores.dtype).min)\n",
    "\n",
    "    attn = F.softmax(scores, dim=-1)\n",
    "    output = torch.matmul(attn, value)\n",
    "    return output, attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-attn out: torch.Size([2, 4, 8])\n",
      "Self-attn attn: torch.Size([2, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 1) Self-attention example\n",
    "# -------------------------\n",
    "B, T, d = 2, 4, 8\n",
    "q = torch.randn(B, T, d)\n",
    "k = torch.randn(B, T, d)\n",
    "v = torch.randn(B, T, d)\n",
    "\n",
    "out, attn = scaled_dot_product_attention(q, k, v)\n",
    "print(\"Self-attn out:\", out.shape)     # (B, T, d)\n",
    "print(\"Self-attn attn:\", attn.shape)   # (B, T, T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Causal out: torch.Size([2, 4, 8])\n",
      "Causal attn: torch.Size([2, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# 2) Causal self-attn (decoder/GPT)\n",
    "# -----------------------------------\n",
    "T = q.size(1)\n",
    "causal_mask = torch.tril(torch.ones(T, T, dtype=torch.bool))  # (T, T) broadcastable\n",
    "out_causal, attn_causal = scaled_dot_product_attention(q, k, v, mask=causal_mask)\n",
    "print(\"Causal out:\", out_causal.shape)        # (B, T, d)\n",
    "print(\"Causal attn:\", attn_causal.shape)      # (B, T, T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-attn out: torch.Size([2, 3, 8])\n",
      "Cross-attn attn: torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# 3) Cross-attention example (enc-dec)\n",
    "#    decoder queries attend over encoder keys/values\n",
    "# -----------------------------------\n",
    "B, T_dec, T_enc, d = 2, 3, 5, 8\n",
    "q_dec = torch.randn(B, T_dec, d)   # decoder states as queries\n",
    "k_enc = torch.randn(B, T_enc, d)   # encoder outputs as keys\n",
    "v_enc = torch.randn(B, T_enc, d)   # encoder outputs as values\n",
    "\n",
    "out_xattn, attn_xattn = scaled_dot_product_attention(q_dec, k_enc, v_enc)\n",
    "print(\"Cross-attn out:\", out_xattn.shape)     # (B, T_dec, d)\n",
    "print(\"Cross-attn attn:\", attn_xattn.shape)   # (B, T_dec, T_enc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad-masked cross-attn out: torch.Size([2, 2, 8])\n",
      "Pad-masked attn: torch.Size([2, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# 4) Padding mask example (variable-length sequences)\n",
    "#    Suppose encoder has padding on the right.\n",
    "# -----------------------------------\n",
    "lengths = torch.tensor([5, 3])  # batch: first has 5 valid, second has 3 valid\n",
    "B, T_enc, d = 2, 5, 8\n",
    "q_dec = torch.randn(B, 2, d)\n",
    "k_enc = torch.randn(B, T_enc, d)\n",
    "v_enc = torch.randn(B, T_enc, d)\n",
    "\n",
    "# mask shape (B, 1, T_enc) -> broadcast to (B, T_dec, T_enc)\n",
    "pad_mask = torch.arange(T_enc).unsqueeze(0) < lengths.unsqueeze(1)  # (B, T_enc) True=valid\n",
    "pad_mask = pad_mask.unsqueeze(1)  # (B, 1, T_enc)\n",
    "\n",
    "out_pad, attn_pad = scaled_dot_product_attention(q_dec, k_enc, v_enc, mask=pad_mask)\n",
    "print(\"Pad-masked cross-attn out:\", out_pad.shape)   # (B, T_dec, d)\n",
    "print(\"Pad-masked attn:\", attn_pad.shape)            # (B, T_dec, T_enc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
